<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>About | Lu Dong</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

  <!-- ðŸ”¹ Navbar -->
  <div class="navbar">
    <div class="nav-container">
      <div class="nav-left">
        <a href="index_yc.html">Home</a>
      </div>
      <div class="nav-right">
        <a href="about_yc.html">About</a>
        <a href="projects_yc.html">Projects</a>
        <a href="publications_yc.html">Publications</a>
        <a href="experience_yc.html">Experience</a>
        <a href="awards_yc.html">Awards</a>
        <a href="photos_yc.html">Photos</a>
      </div>
    </div>
  </div>

  <div class="container">
    <h2>About Me</h2>
    <p>
      I am a Ph.D. student (2021â€“Present) at the Department of Computer Science and Engineering, 
      University at Buffalo (UB), advised by <a href="https://scholar.google.com/citations?user=pCOmTY0AAAAJ&hl=en" target="_blank">Prof. Ifeoma Nwogu</a> at the Human Behavior Modeling Lab.
      Prior to that, I received my Master's degree in Computer Science and Technology at 
      <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University</a> under the supervision of 
      <a href="https://gr.xjtu.edu.cn/web/xyyang">Prof. Xinyu Yang</a>.
    </p>

    <p>
      My research focuses on computer vision, large language models (LLMs), 3D human body and face modeling, and AI-generated content (AIGC). I am particularly interested in their applications to human behavior understanding, sign language synthesis, child-centered education technology, and VR/AR interaction design.
    </p>

    <h2>Education</h2>
    <ul>
      <li><strong>Ph.D. in Computer Science and Engineering</strong>, University at Buffalo, SUNY, USA (2021â€“Present)</li>
      <li><strong>M.S. in Computer Science and Technology</strong>, Xi'an Jiaotong University, China (2013â€“2016)</li>
      <li><strong>B.Eng. in Computer Science</strong>, Xi'an Jiaotong University, China (2009â€“2013)</li>
    </ul>

    <h2>Research Topics</h2>
    <ul>
      <li>Large Language Models (LLMs) & Human-Robot Collaboration</li>
      <li>3D Human Body & Face Modeling</li>
      <li>AI-Generated Content (AIGC) & Sign Language Synthesis</li>
      <li>Computer Vision for Nonverbal Behavior Understanding</li>
      <li>Educational AI for Children & VR/AR Interaction</li>
    </ul>

    <h2>Research Goals</h2>
    <p>
      My long-term goal is to develop robust and socially-aware AI systems that can understand, interpret, and interact with human behaviorsâ€”especially those of underrepresented or vulnerable populations, including children and individuals with disabilities. I strive to bridge technical research with real-world impact through inclusive, accessible, and explainable intelligent systems.
    </p>
  </div>

  <!-- ðŸ”¹ Footer -->
  <div class="footer">
    About Â© Lu Dong | Last updated May 2025
  </div>

</body>
</html>
